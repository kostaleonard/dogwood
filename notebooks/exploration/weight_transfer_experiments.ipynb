{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56578c9a",
   "metadata": {},
   "source": [
    "# Weight transfer experiments\n",
    "\n",
    "In this notebook, we conduct weight transfer experiments on MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae6585d",
   "metadata": {},
   "source": [
    "## Change working directory to project root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0957fbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ROOT_DIRECTORIES = {'dogwood', 'tests'}\n",
    "if set(os.listdir('.')).intersection(ROOT_DIRECTORIES) != ROOT_DIRECTORIES:\n",
    "    os.chdir('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c166dacd",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774205ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from dogwood.weight_transfer import are_symmetric_dense_neurons, \\\n",
    "    expand_dense_layer, expand_dense_layers, clone_layer\n",
    "\n",
    "MAX_PIXEL_VALUE = 255\n",
    "MNIST_IMAGE_SHAPE = (28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6070e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO should we make MNIST a versioned dataset?\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = tf.cast(X_train, tf.float32) / MAX_PIXEL_VALUE\n",
    "X_test = tf.cast(X_test, tf.float32) / MAX_PIXEL_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674258d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_small_model(num_hidden=1):\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=MNIST_IMAGE_SHAPE, name='flatten'),\n",
    "        Dense(num_hidden, activation='relu', name='dense_1'),\n",
    "        Dense(10, activation='softmax', name='dense_2')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['sparse_categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e029a5",
   "metadata": {},
   "source": [
    "**One hidden layer weight expansion experiment on MNIST**\n",
    "\n",
    "In this experiment, we compare the training progress of models trained from scratch against those with partially pretrained weights. We also compare their performance on the test data after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53bd449",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 20\n",
    "from_scratch_histories = {}\n",
    "from_scratch_eval = {}\n",
    "expanded_histories = {}\n",
    "expanded_eval = {}\n",
    "expanded_model = None\n",
    "for num_hidden in range(1, 6):\n",
    "    from_scratch_model = get_small_model(num_hidden)\n",
    "    history = from_scratch_model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)\n",
    "    from_scratch_histories[num_hidden] = history\n",
    "    acc = from_scratch_model.evaluate(X_test, y_test)[1]\n",
    "    from_scratch_eval[num_hidden] = acc\n",
    "    # The first iteration, the expanded model is created from scratch.\n",
    "    # Every other iteration, expand.\n",
    "    if not expanded_model:\n",
    "        expanded_model = get_small_model(num_hidden)\n",
    "    else:\n",
    "        expanded_model = expand_dense_layer(expanded_model, 'dense_1', 1)\n",
    "        expanded_model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['sparse_categorical_accuracy'])\n",
    "    history = expanded_model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)\n",
    "    expanded_histories[num_hidden] = history\n",
    "    acc = expanded_model.evaluate(X_test, y_test)[1]\n",
    "    expanded_eval[num_hidden] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf2ee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "for num_hidden in sorted(from_scratch_histories.keys()):    \n",
    "    plt.plot(from_scratch_histories[num_hidden].history['sparse_categorical_accuracy'], '-', label=f'S{num_hidden}')\n",
    "    plt.plot(expanded_histories[num_hidden].history['sparse_categorical_accuracy'], 'o', label=f'E{num_hidden}')\n",
    "plt.legend()\n",
    "plt.title('From scratch (S) vs expanded (E) model training history')\n",
    "plt.xlim([0, epochs])\n",
    "plt.ylim([0, 1])\n",
    "plt.xticks(list(range(epochs)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8345132",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "for num_hidden in sorted(from_scratch_eval.keys()):    \n",
    "    plt.scatter(-0.1, from_scratch_eval[num_hidden], marker='x', label=f'S{num_hidden}')\n",
    "    plt.scatter(0.1, expanded_eval[num_hidden], marker='o', label=f'E{num_hidden}')\n",
    "plt.legend()\n",
    "plt.title('From scratch (S) vs expanded (E) model test accuracy')\n",
    "plt.xlim([-1, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xticks([0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201ab84b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
