{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09715aa0",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "\n",
    "This notebook explores transfer learning techniques on MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caef3d3e",
   "metadata": {},
   "source": [
    "## Change working directory to project root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79842ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ROOT_DIRECTORIES = {'dogwood', 'tests'}\n",
    "if set(os.listdir('.')).intersection(ROOT_DIRECTORIES) != ROOT_DIRECTORIES:\n",
    "    os.chdir('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf12af6",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ed6447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.initializers import Constant, GlorotUniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c104fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_IMAGE_SHAPE = (28, 28)\n",
    "MAX_PIXEL_VALUE = 255\n",
    "MODEL_SAVE_DIR = '/tmp/dogwood/mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4057a7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = tf.cast(X_train, tf.float32) / MAX_PIXEL_VALUE\n",
    "X_test = tf.cast(X_test, tf.float32) / MAX_PIXEL_VALUE\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d9b1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(MNIST_IMAGE_SHAPE), name='flatten'),\n",
    "    Dense(128, activation='relu', name='dense_1'),\n",
    "    Dense(10, activation='softmax', name='dense_2')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137825bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de363ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1db5af4",
   "metadata": {},
   "source": [
    "## Small model\n",
    "\n",
    "We will train a smaller model so that it is easier to work with the weight matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8089d790",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(MNIST_IMAGE_SHAPE), name='flatten'),\n",
    "    Dense(1, activation='relu', name='dense_1'),\n",
    "    Dense(10, activation='softmax', name='dense_2')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2871dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2c0d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3442b7",
   "metadata": {},
   "source": [
    "## New models using (sometimes partially) pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8778e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(MODEL_SAVE_DIR).mkdir(parents=True, exist_ok=True)\n",
    "model_path = os.path.join(MODEL_SAVE_DIR, 'model.h5')\n",
    "model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e04d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(model_path, 'r') as infile:\n",
    "    print(infile.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d02676",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(model_path, 'r') as infile:\n",
    "    print(infile['flatten'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361b0c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(model_path, 'r') as infile:\n",
    "    print(infile['dense_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1754103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(model_path, 'r') as infile:\n",
    "    print(infile['dense_1'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d0c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(model_path, 'r') as infile:\n",
    "    print(infile['dense_1']['dense_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e312bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(model_path, 'r') as infile:\n",
    "    print(infile['dense_1']['dense_1'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328a08a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(model_path, 'r') as infile:\n",
    "    print(infile['dense_1']['dense_1']['bias:0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c965a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(model_path, 'r') as infile:\n",
    "    print(infile['dense_1']['dense_1']['kernel:0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac084449",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(model_path, 'r') as infile:\n",
    "    print(infile['dense_2']['dense_2']['kernel:0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc760b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(model_path, 'r') as infile:\n",
    "    biases_1 = infile['dense_1']['dense_1']['bias:0'][:]\n",
    "    weights_1 = infile['dense_1']['dense_1']['kernel:0'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21348543",
   "metadata": {},
   "source": [
    "We can visualize these weights in a 2D plot, although they make more sense in 28 x 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94438530",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Cell temporarily disabled because not very interesting.\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "heatmap = ax.pcolor(weights_1.T, cmap=plt.cm.Blues)\n",
    "cbar = ax.figure.colorbar(heatmap, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc73be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Cell temporarily disabled because not very interesting.\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "heatmap = ax.pcolor(np.expand_dims(biases_1, axis=-1), cmap=plt.cm.Blues)\n",
    "cbar = ax.figure.colorbar(heatmap, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16343fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Cell temporarily disabled because not very interesting.\n",
    "figs, axes = plt.subplots(ncols=2, figsize=(12, 8))\n",
    "heatmap_weights = axes[0].pcolor(weights_1.T, cmap=plt.cm.Blues)\n",
    "heatmap_biases = axes[1].pcolor(np.expand_dims(biases_1, axis=-1), cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb743fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential([\n",
    "    Flatten(input_shape=(MNIST_IMAGE_SHAPE), name='flatten'),\n",
    "    Dense(1, activation='relu', name='dense_1'),\n",
    "    Dense(10, activation='softmax', name='dense_2')\n",
    "])\n",
    "model_2.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72d1630",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f7d442",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da46ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.predict(X_test)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bec1f2b",
   "metadata": {},
   "source": [
    "Identical loss and accuracy from the loaded weights when the architecture is identical. This is as expected. Now we will add a neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65745f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Sequential([\n",
    "    Flatten(input_shape=(MNIST_IMAGE_SHAPE), name='flatten'),\n",
    "    Dense(2, activation='relu', name='dense_1'),\n",
    "    Dense(10, activation='softmax', name='dense_2')\n",
    "])\n",
    "model_3.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bcc1c6",
   "metadata": {},
   "source": [
    "We will now artificially construct a weights file such that there is no performance decrease with the new architecture. See notes for how this is done. In brief, the weights and bias leading into the new neuron can be arbitrary, but the weights leading out must be 0. The bias unit in the new neuron's layer is unaffected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82d5820",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3_path = os.path.join(MODEL_SAVE_DIR, 'model_3.h5')\n",
    "model_2.save_weights(model_3_path)\n",
    "with h5py.File(model_3_path, 'r+') as outfile:\n",
    "    # Dense 1.\n",
    "    group = outfile['dense_1']['dense_1']\n",
    "    print(group['bias:0'])\n",
    "    arr = np.concatenate((group['bias:0'][:], np.zeros((1,))), axis=0)\n",
    "    print(arr.shape)\n",
    "    del group['bias:0']\n",
    "    group.create_dataset('bias:0', (2,), dtype='<f4', data=arr)\n",
    "    print(group['bias:0'])\n",
    "    print(group['kernel:0'])\n",
    "    arr = np.concatenate((group['kernel:0'][:], np.zeros((784, 1))), axis=1)\n",
    "    print(arr.shape)\n",
    "    del group['kernel:0']\n",
    "    group.create_dataset('kernel:0', (784, 2), dtype='<f4', data=arr)\n",
    "    print(group['kernel:0'])\n",
    "    # Dense 2.\n",
    "    group = outfile['dense_2']['dense_2']\n",
    "    print(group['kernel:0'])\n",
    "    arr = np.concatenate((group['kernel:0'][:], np.zeros((1, 10))), axis=0)\n",
    "    print(arr.shape)\n",
    "    del group['kernel:0']\n",
    "    group.create_dataset('kernel:0', (2, 10), dtype='<f4', data=arr)\n",
    "    print(group['kernel:0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305d57fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.load_weights(model_3_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4251f420",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5b9a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.predict(X_test)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a56197",
   "metadata": {},
   "source": [
    "We have successfully added a neuron and preserved loss and accuracy. Now let's train the new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73687988",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad27cfbf",
   "metadata": {},
   "source": [
    "The model above uses zeros as the initialization for all weights. However, based on the gradient calculations from our research notes, we should only initialize weights from new nodes to old nodes to zero; all other weights should be randomly initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b00f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "glorot = GlorotUniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41f46a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3_path = os.path.join(MODEL_SAVE_DIR, 'model_3.h5')\n",
    "model_2.save_weights(model_3_path)\n",
    "with h5py.File(model_3_path, 'r+') as outfile:\n",
    "    # Dense 1.\n",
    "    group = outfile['dense_1']['dense_1']\n",
    "    print(group['bias:0'])\n",
    "    # By default, dense layers use zeros as their bias initializers.\n",
    "    arr = np.concatenate((group['bias:0'][:], np.zeros((1,))), axis=0)\n",
    "    print(arr.shape)\n",
    "    del group['bias:0']\n",
    "    group.create_dataset('bias:0', (2,), dtype='<f4', data=arr)\n",
    "    print(group['bias:0'])\n",
    "    print(group['kernel:0'])\n",
    "    # Initialize as if we want the full array; take only one column.\n",
    "    initialization = glorot((784, 2))[:, :1]\n",
    "    arr = np.concatenate((group['kernel:0'][:], initialization), axis=1)\n",
    "    print(arr.shape)\n",
    "    del group['kernel:0']\n",
    "    group.create_dataset('kernel:0', (784, 2), dtype='<f4', data=arr)\n",
    "    print(group['kernel:0'])\n",
    "    # Dense 2.\n",
    "    group = outfile['dense_2']['dense_2']\n",
    "    print(group['kernel:0'])\n",
    "    arr = np.concatenate((group['kernel:0'][:], np.zeros((1, 10))), axis=0)\n",
    "    print(arr.shape)\n",
    "    del group['kernel:0']\n",
    "    group.create_dataset('kernel:0', (2, 10), dtype='<f4', data=arr)\n",
    "    print(group['kernel:0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8161c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.load_weights(model_3_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141a4f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc400c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.predict(X_test)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408b0518",
   "metadata": {},
   "source": [
    "As expected, the weight initialization scheme for the first dense layer weights did not affect the output because the new weights in the second dense layer are still 0. Now we will train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5bb598",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e842873",
   "metadata": {},
   "source": [
    "What if we trained it from scratch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Sequential([\n",
    "    Flatten(input_shape=(MNIST_IMAGE_SHAPE), name='flatten'),\n",
    "    Dense(2, activation='relu', name='dense_1'),\n",
    "    Dense(10, activation='softmax', name='dense_2')\n",
    "])\n",
    "model_3.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdeba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81196d1",
   "metadata": {},
   "source": [
    "In this case, when intermediate weights are properly initialized, training from a partially pretrained neural network and training from scratch result in models of approximately equal performance. There is no clear advantage to either approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3b1b50",
   "metadata": {},
   "source": [
    "## Weight symmetry tests\n",
    "\n",
    "Gradient descent forces us to randomly initialize neural network weights, otherwise we have the problem of weight symmetry. Weight symmetry causes all nodes to compute the same function, so your predictive power is dramatically decreased. Based on math done in the notes, we can get around this by randomly initializing the weights going into the new neurons, but we can still set the outgoing weights to zero, preserving performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7159f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = Sequential([\n",
    "    Flatten(input_shape=(MNIST_IMAGE_SHAPE), name='flatten'),\n",
    "    Dense(128, activation='relu', name='dense_1',\n",
    "          kernel_initializer=Constant(0)),\n",
    "    Dense(10, activation='softmax', name='dense_2',\n",
    "          kernel_initializer=Constant(0))\n",
    "])\n",
    "model_4.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5f11d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a6b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = Sequential([\n",
    "    Flatten(input_shape=(MNIST_IMAGE_SHAPE), name='flatten'),\n",
    "    Dense(128, activation='relu', name='dense_1'),\n",
    "    Dense(10, activation='softmax', name='dense_2',\n",
    "          kernel_initializer=Constant(0))\n",
    "])\n",
    "model_5.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f967c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c5eeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6 = Sequential([\n",
    "    Flatten(input_shape=(MNIST_IMAGE_SHAPE), name='flatten'),\n",
    "    Dense(128, activation='relu', name='dense_1',\n",
    "          kernel_initializer=Constant(0)),\n",
    "    Dense(128, activation='relu', name='dense_1a',\n",
    "          kernel_initializer=Constant(0)),\n",
    "    Dense(10, activation='softmax', name='dense_2',\n",
    "          kernel_initializer=Constant(0))\n",
    "])\n",
    "model_6.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c341b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7 = Sequential([\n",
    "    Flatten(input_shape=(MNIST_IMAGE_SHAPE), name='flatten'),\n",
    "    Dense(128, activation='relu', name='dense_1'),\n",
    "    Dense(128, activation='relu', name='dense_1a',\n",
    "          kernel_initializer=Constant(0)),\n",
    "    Dense(10, activation='softmax', name='dense_2',\n",
    "          kernel_initializer=Constant(0))\n",
    "])\n",
    "model_7.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6619b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b65340",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8 = Sequential([\n",
    "    Flatten(input_shape=(MNIST_IMAGE_SHAPE), name='flatten'),\n",
    "    Dense(128, activation='relu', name='dense_1',\n",
    "          kernel_initializer=Constant(0)),\n",
    "    Dense(128, activation='relu', name='dense_1a'),\n",
    "    Dense(10, activation='softmax', name='dense_2',\n",
    "          kernel_initializer=Constant(0))\n",
    "])\n",
    "model_8.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c1b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c478243",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_9 = Sequential([\n",
    "    Flatten(input_shape=(MNIST_IMAGE_SHAPE), name='flatten'),\n",
    "    Dense(128, activation='relu', name='dense_1',\n",
    "          kernel_initializer=Constant(0)),\n",
    "    Dense(128, activation='relu', name='dense_1a'),\n",
    "    Dense(10, activation='softmax', name='dense_2')\n",
    "])\n",
    "model_9.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c6f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_9.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2768c3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
